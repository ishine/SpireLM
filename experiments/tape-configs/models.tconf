global {
    text2text_model=(
        Text2TextModel:
            tower_base="Unbabel/TowerBase-7B-v0.1"
            tower_instruct="Unbabel/TowerInstruct-7B-v0.1"
            tower_instruct_13B="Unbabel/TowerInstruct-13B-v0.1"
            spire_base="utter-project/SpireBase"
            spire_no_pseudo="utter-project/SpireNoPseudo"
            spire_full="utter-project/SpireFull"
            spire_no_blocks="utter-project/SpireNoBlocks"
            tower_full="utter-project/TowerFull"
            seamless="facebook/seamless-m4t-v2-large"
    )

    text2text_tokenizer=(
        Text2TextModel:
            tower_base="Unbabel/TowerBase-7B-v0.1"
            tower_instruct="Unbabel/TowerInstruct-7B-v0.1"
            tower_instruct_13B="Unbabel/TowerInstruct-13B-v0.1"
            spire_base="utter-project/SpireBase"
            spire_no_pseudo="utter-project/SpireNoPseudo"
            spire_full="utter-project/SpireFull"
            spire_no_blocks="utter-project/SpireNoBlocks"
            tower_full="utter-project/TowerFull"
            seamless="facebook/seamless-m4t-v2-large"
    )

    speech2text_model=(
        Speech2TextModel:
            spire_base="utter-project/SpireBase"
            spire_no_pseudo="utter-project/SpireNoPseudo"
            spire_full="utter-project/SpireFull"
            spire_no_blocks="utter-project/SpireNoBlocks"
            tower_full="utter-project/TowerFull"
            seamless="facebook/seamless-m4t-v2-large"
            whisper="openai/whisper-large-v3"
            whisper_medium="openai/whisper-medium"
            whisper_small="openai/whisper-small"
            whisper_base="openai/whisper-base"
    )

    speech2text_tokenizer=(
        Speech2TextModel:
            spire_base="utter-project/SpireBase"
            spire_no_pseudo="utter-project/SpireNoPseudo"
            spire_full="utter-project/SpireFull"
            spire_no_blocks="utter-project/SpireNoBlocks"
            tower_full="utter-project/TowerFull"
            seamless="facebook/seamless-m4t-v2-large"
            whisper="openai/whisper-large-v3"
            whisper_medium="openai/whisper-medium"
            whisper_small="openai/whisper-small"
            whisper_base="openai/whisper-base"
    )

    seamless_batch_size=16
    whisper_batch_size=32

    speech_to_text_backend=(
        Speech2TextModel:
            spire_base=vllm
            spire_no_pseudo=vllm
            spire_full=vllm
            spire_no_blocks=vllm
            tower_full=vllm
            seamless=hf
            whisper=hf
            whisper_medium=hf
            whisper_small=hf
            whisper_base=hf
    )

    text_to_text_backend=(
        Text2TextModel:
            tower_base=vllm
            tower_instruct=vllm
            tower_instruct_13B=vllm
            spire_base=vllm
            spire_no_pseudo=vllm
            spire_full=vllm
            spire_no_blocks=vllm
            tower_full=vllm
            seamless=hf
    )

    input_format=(
        Speech2TextModel:
            spire_base=json
            spire_no_pseudo=json
            spire_full=json
            spire_no_blocks=json
            tower_full=json
            seamless=wav_tsv
            whisper=wav_tsv
            whisper_medium=wav_tsv
            whisper_small=wav_tsv
            whisper_base=wav_tsv
    )
    text_input_format=(
        Text2TextModel:
            tower_base=json
            tower_instruct=json
            tower_instruct_13B=json
            spire_base=json
            spire_no_pseudo=json
            spire_full=json
            spire_no_blocks=json
            tower_full=json
            seamless=raw_text
    )
    batch_size=(
        Speech2TextModel:
            spire_base=1
            spire_no_pseudo=1
            spire_full=1
            spire_no_blocks=1
            tower_full=1
            seamless=4
            whisper=32
            whisper_medium=32
            whisper_small=64
            whisper_base=64
    )
}
